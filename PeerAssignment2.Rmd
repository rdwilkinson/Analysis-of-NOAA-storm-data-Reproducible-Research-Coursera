---
title: "PeerAssignment2"
author: "Richard D. Wilkinson"
date: "03/11/2020"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Synopsis


# Data processing
## Pre-processing
Check if the dataset is already available in the adequate folder, otherwise create this and download it.
```{r}
if (!dir.exists(file.path("data"))) {
  dir.create(file.path("data"))
} 

if (!file.exists("data/StormData.csv.bz2")) {
  download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", "data/StormData.csv.bz2")
}
```

Load the data into the environment.
```{r}
stormData <- read.csv("data/StormData.csv.bz2", header = TRUE, sep = ",")
head(stormData)
```

Get an idea of how the dataset is structured.
```{r}
names(stormData)
head(stormData)
```
Keep the variables of interest for the analysis and make sure they are of the correct type (switch the event type variable to a factor).
```{r}
newStormData <- stormData[, c("REFNUM", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP",  "EVTYPE", "BGN_DATE", "REMARKS")]

for (i in 1:dim(newStormData)[2]) {
  str(newStormData[i])
}

stormData$EVTYPE <- as.factor(stormData$EVTYPE)
```

### Do we have event types for every year in the dataset?
The date is not in a format that is recognisable by R. Let's strip the year from the BGN_DATE variable.

```{r}
head(newStormData)

library(tidyverse)

newStormData$newDate <- str_split_fixed(newStormData$BGN_DATE, " ", 2)[, 1]
newStormData$newYear <- str_split_fixed(newStormData$newDate, "/", 3)[, 3]

missingEventTypes <- newStormData %>%
  group_by(newYear) %>%
  summarise(SumEventTypes = sum(is.na(EVTYPE)))

head(missingEventTypes)
```
There are no years with missing event types.

### What level of consistency was achieved in the categorisation of the events?
```{r}
head(unique(newStormData$EVTYPE))
```

There are 985 different types of storm events. Some of these categories could be collapsed (e.g. "FLASH FLOOD LANDSLIDES" & "FLASH FLOOD/LANDSLIDE"). Others are not actually storm types (e.g. "Summary of March 14"). It is assumed that more catastrophic events will have been coded more consistently, so event categories are not collapsed here. Nevertheless, records with event types labelled as "summar*" are removed from the dataset.
```{r}
newStormData$EVTYPE <- toupper(newStormData$EVTYPE)

newStormData$EVTYPE2 <- newStormData$EVTYPE
newStormData$EVTYPE2[str_detect(newStormData$EVTYPE, "SUMMAR") == TRUE] <- NA
sum(is.na(newStormData$EVTYPE2))

newStormData[!is.na(newStormData$EVTYPE2),]
```

### Distribution of the estimates of injured and fatalities
```{r}
summary(newStormData$INJURIES)
summary(newStormData$FATALITIES)
```

### Preparing the damage estimates
Damage is measured bidimensionally in the dataset, through an estimate of the cost of damage to property, as well as of the cost of damage to crops. Both estimates, as printed in the NOAA reports, comprise a base estimate and a multiplier. However, apart from h = hundred, k = thousand, m = million and b = billion, the labels are unclear ("", "?", "0", "+").
```{r}
unique(newStormData$PROPDMGEXP)
unique(newStormData$CROPDMGEXP)
```

Let's make all the mutipliers uppercase to collapse some of the categories.
```{r}
newStormData$PROPDMGEXP <- toupper(newStormData$PROPDMGEXP)
newStormData$CROPDMGEXP <- toupper(newStormData$CROPDMGEXP)
```

Can the meaning of the numbered values be guessed qualitatively from the remarks? Let's compare some of these.
```{r}
m0 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "0" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m1 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "1" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m2 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "2" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m3 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "3" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m4 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "4" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m5 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "5" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m6 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "6" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m7 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "7" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)
m8 <- head(newStormData$REMARKS[newStormData$PROPDMGEXP == "8" & newStormData$REMARKS != "" & newStormData$REMARKS != "  "], 2)

listRemarks <- list(M0 = m0, M1 = m1, M2 = m2, M3 = m3, M4 = m4, 
                    M5 = m5, M6 = m6, M7 = m7, M8 = m8)

listRemarks

newStormData$PROPDMGEXP.num[newStormData$PROPDMGEXP == ""]
```
There does seem to be some level of gradation in these descriptions. Hence, it seems as though there are two competing measurement systems: the h, k, m, b system and a numeric scale ranging from 0 to 7.

Which is the most frequently used?

```{r}
out <- newStormData %>%
  group_by(PROPDMGEXP) %>%
  summarise(totalEvents = sum(EVTYPE2))
  
```


... and recode the values as numeric multipliers.


## Analysis

```{r}

```



# Results